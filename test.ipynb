{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DataGenerator\n",
    "from utils import *\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path = os.path.join(CWD, 'glove.6B/glove.6B.100d.txt')\n",
    "embeddings_index = load_embeddings(embeddings_path)\n",
    "embedding_dim = 100\n",
    "captions_path = os.path.join(CWD, 'data/captions.txt')\n",
    "caption_dict = preprocess_captions(captions_path)\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "vocab = get_vocab(caption_dict)\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "vocab_size = len(vocab) + 1\n",
    "embedding_matrix = create_embedding_matrix(tokenizer, vocab_size, embeddings_index, embedding_dim)\n",
    "max_seq_length = get_max_length(caption_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = os.path.join(CWD, 'encodings.pkl')\n",
    "with open(features_path, 'rb') as f:\n",
    "    features_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = DataGenerator(caption_dict, features_dict, tokenizer, max_seq_length, vocab_size, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[0.12277604, 0.3329488 , 0.7527181 , ..., 0.21939662, 0.3021642 ,\n",
       "          0.40283287],\n",
       "         [0.12277604, 0.3329488 , 0.7527181 , ..., 0.21939662, 0.3021642 ,\n",
       "          0.40283287],\n",
       "         [0.12277604, 0.3329488 , 0.7527181 , ..., 0.21939662, 0.3021642 ,\n",
       "          0.40283287],\n",
       "         ...,\n",
       "         [0.12277604, 0.3329488 , 0.7527181 , ..., 0.21939662, 0.3021642 ,\n",
       "          0.40283287],\n",
       "         [0.12277604, 0.3329488 , 0.7527181 , ..., 0.21939662, 0.3021642 ,\n",
       "          0.40283287],\n",
       "         [0.12277604, 0.3329488 , 0.7527181 , ..., 0.21939662, 0.3021642 ,\n",
       "          0.40283287]], dtype=float32),\n",
       "  array([[   0,    0,    0, ...,    0,    0, 3700],\n",
       "         [   0,    0,    0, ...,    0, 3700, 1128],\n",
       "         [   0,    0,    0, ..., 3700, 1128, 3904],\n",
       "         ...,\n",
       "         [   0,    0,    0, ..., 3475, 1395, 1050],\n",
       "         [   0,    0,    0, ..., 1395, 1050, 3714],\n",
       "         [   0,    0,    0, ..., 1050, 3714, 2432]], dtype=int32)],\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = next(iter(data_gen))\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a, b], c = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq:  ['<start> child in pink dress is']\n",
      "next word:  ['climbing']\n"
     ]
    }
   ],
   "source": [
    "seq = tokenizer.sequences_to_texts([b[5]])\n",
    "next_word = tokenizer.sequences_to_texts([[np.argmax(c[5])]])\n",
    "print('seq: ', seq)\n",
    "print('next word: ', next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_vals = (np.array(features_dict['1000268201_693b08cb0e.jpg']) == a[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in truth_vals:\n",
    "    if not i:\n",
    "        print('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
